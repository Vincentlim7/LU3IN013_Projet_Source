{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use the UniRep mLSTM \"babbler\". This version demonstrates the 64-unit and the 1900-unit architecture. \n",
    "\n",
    "We recommend getting started with the 64-unit architecture as it is easier and faster to run, but has the same interface as the 1900-unit one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the 64-unit or the 1900-unit model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_FULL_1900_DIM_MODEL = False # if True use 1900 dimensional model, else use 64 dimensional one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to allow autoreload of utils.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import utils # our functions\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "if USE_FULL_1900_DIM_MODEL:\n",
    "    # Sync relevant weight files\n",
    "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/1900_weights/ 1900_weights/\n",
    "    \n",
    "    # Import the mLSTM babbler model\n",
    "    from unirep import babbler1900 as babbler\n",
    "    \n",
    "    # Where model weights are stored.\n",
    "    MODEL_WEIGHT_PATH = \"./1900_weights\"\n",
    "    \n",
    "else:\n",
    "    # Sync relevant weight files\n",
    "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/64_weights/ 64_weights/\n",
    "    \n",
    "    # Import the mLSTM babbler model\n",
    "    from unirep import babbler64 as babbler\n",
    "    \n",
    "    # Where model weights are stored.\n",
    "    MODEL_WEIGHT_PATH = \"./64_weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting and management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize UniRep, also referred to as the \"babbler\" in our code. You need to provide the batch size you will use and the path to the weight directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "b = babbler(batch_size=batch_size, model_path=MODEL_WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize database and save in binary files with numpy.save(\"path to files\", data to save)\n",
    "Once the binary files are created, there is no need to execute this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_start_time = time.time()\n",
    "classes_avg, classes_concat = utils.dic_init()\n",
    "total_elapsed_time = time.time() - total_start_time\n",
    "print(total_elapsed_time)\n",
    "np.save(\"dataset/avg/data_avg.npy\", classes_avg)\n",
    "np.save(\"dataset/concat/data_concat.npy\", classes_concat)\n",
    "\n",
    "dist_intra_avg, stats_intra_avg = utils.get_dist_intra(classes_avg)\n",
    "dist_intra_concat, stats_intra_concat = utils.get_dist_intra(classes_concat)\n",
    "np.save(\"dataset/avg/dist_intra_avg.npy\", dist_intra_avg)\n",
    "np.save(\"dataset/concat/dist_intra_concat.npy\", dist_intra_concat)\n",
    "np.save(\"dataset/avg/stats_intra.npy\", stats_intra_avg)\n",
    "np.save(\"dataset/concat/stats_intra.npy\", stats_intra_concat)\n",
    "\n",
    "dist_extra_avg, stats_extra_avg = utils.get_dist_extra(classes_avg)\n",
    "dist_extra_concat, stats_extra_concat = utils.get_dist_extra(classes_concat)\n",
    "np.save(\"dataset/avg/dist_extra_avg.npy\", dist_extra_avg)\n",
    "np.save(\"dataset/concat/dist_extra_concat.npy\", dist_extra_concat)\n",
    "np.save(\"dataset/avg/stats_extra.npy\", stats_extra_avg)\n",
    "np.save(\"dataset/concat/stats_extra.npy\", stats_extra_concat)\n",
    "\n",
    "utils.seuil_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data with numpy.load(\"path to binary file containing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes_avg = np.load(\"dataset/avg/data_avg.npy\")[()]\n",
    "dist_intra_avg = np.load(\"dataset/avg/dist_intra_avg.npy\")[()]\n",
    "dist_extra_avg = np.load(\"dataset/avg/dist_extra_avg.npy\")[()]\n",
    "stat_intra_avg = np.load(\"dataset/avg/stats_intra.npy\")\n",
    "seuil_avg = np.load(\"dataset/avg/seuil.npy\")[()]\n",
    "stat_extra_avg = np.load(\"dataset/avg/stats_extra.npy\")\n",
    "\n",
    "classes_concat = np.load(\"dataset/concat/data_concat.npy\")[()]\n",
    "dist_intra_concat = np.load(\"dataset/concat/dist_intra_concat.npy\")[()]\n",
    "dist_extra_concat = np.load(\"dataset/concat/dist_extra_concat.npy\")[()]\n",
    "stat_intra_concat = np.load(\"dataset/concat/stats_intra.npy\")\n",
    "stat_extra_concat = np.load(\"dataset/concat/stats_extra.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.histo(dist_intra_avg, dist_extra_avg, avg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utils.histo(dist_intra_concat, dist_extra_concat, avg = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.inf\n",
    "for distance in dist_intra_avg[\"a.1.1.1\"].values():\n",
    "    print(distance[1])\n",
    "    if distance[1] < res:\n",
    "        res = distance[1]\n",
    "print(res)\n",
    "print(\"-----------\")\n",
    "seuil_intra = np.inf\n",
    "for protein, distance in dist_intra_avg[\"a.1.1.1\"].values():\n",
    "    print(distance)\n",
    "    if distance < seuil_intra:\n",
    "        seuil_intra = distance\n",
    "print(seuil_intra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.seuil_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seuil = np.load(\"dataset/avg/seuil.npy\")[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.test3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
